<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - Tag - Ryutaro note</title>
        <link>https://ryutaro-a.github.io/ryutaro1104/tags/python/</link>
        <description>Python - Tag - Ryutaro note</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 29 May 2022 12:38:06 &#43;0900</lastBuildDate><atom:link href="https://ryutaro-a.github.io/ryutaro1104/tags/python/" rel="self" type="application/rss+xml" /><item>
    <title>Google Colabでfairseq入門</title>
    <link>https://ryutaro-a.github.io/ryutaro1104/fairseq-env/</link>
    <pubDate>Sun, 29 May 2022 12:38:06 &#43;0900</pubDate><guid>https://ryutaro-a.github.io/ryutaro1104/fairseq-env/</guid>
    <description><![CDATA[はじめに こんにちは！りゅうです。
今日は最近？流行っているfairseqをColabを使って簡単に動かす方法を紹介します。
私が指導教授や研究室の同期に触発されて、Colabで動かそうと思ったときにそのままでは動かなかったので備忘録としてその手順をここに書いておこうと思います。（ちなみに1回動かして以降使ってない・・・）
ちなみにfairseqとは、Facebookの人工知能研究チームが開発した機械学習用(主にTransformer)のフレームワークです。
Pytorchで作成されていることから有志によって確立された改造方法も存在し、論文でも見かけたりと、研究でも使われるようになっていると思います。
以下公式GitHub↓

参考 
fairseqの導入 fairseqのインストールは公式Githubにあるものをそのままコピーして使います。
1 2 3  git clone https://github.com/pytorch/fairseq cd fairseq pip install --editable ./   上記コマンドでインストールしてから
1 2 3 4  fairseq-train #エラー文 No package metadata was found for fairseq   コマンドを試しに打ってみた際に発生したエラーです。
公式githubのissueによるとパスが通っていないことが原因のようでした。
そこで以下のようにPYTHONPATHにfairseqがある場所を追加してあげます。
1 2 3 4  import os os.environ[&#39;PYTHONPATH&#39;] += &#34;:/content/fairseq/&#34; ! echo $PYTHONPATH   この操作でパスが通ってfairseq-trainなどのコマンドが使えるようになります。
fairseq本体ディレクトリのパスさえ通せばいいので、パスの部分は適宜書き換えて使ってみてください。
それでは良きfairseqライフを。]]></description>
</item>
<item>
    <title>SVMで超機械学習入門！</title>
    <link>https://ryutaro-a.github.io/ryutaro1104/fundamental_svm/</link>
    <pubDate>Sun, 29 May 2022 12:38:06 &#43;0900</pubDate><guid>https://ryutaro-a.github.io/ryutaro1104/fundamental_svm/</guid>
    <description><![CDATA[はじめに 機械学習に関する入門サイト見ていると、難しいことが書いてあったりして、知識０の人がとっつきにくい印象があります。 まあテーマとして確かに難しいのでしょうがないですが&hellip;. 「数学や機械学習の知識が0でも、pythonの知識さえあれば誰でも実装できる」というのを目標に記事を書いていきたいと思います。 今回の記事では難しいことは説明せず、とりあえず機械学習というものに触れてみるというスタンスで、進めていきます。
対象者 ・pythonがある程度わかる ・機械学習に興味があるけど、何も知らない ・大学の授業で概要は学んだけど、実際にどう実装すればいいかわからない
環境 python 3.8.5 scikit-learn 0.231 ##まずはインストール
1  pip install scikit-learn   csvファイルの読み込みにnumpyを使うのでインストール済みでない方はインストールしてください。
1  pip install numpy   用語解説 ######scikit-learnとは scikit-learn （サイキット・ラーン）(旧称：scikits.learn) はPythonのオープンソース機械学習ライブラリ[2]である。サポートベクターマシン、ランダムフォレスト、Gradient Boosting（英語版）、k近傍法、DBSCANなどを含む様々な分類、回帰、クラスタリングアルゴリズムを備えており、Pythonの数値計算ライブラリのNumPyとSciPyとやり取りするよう設計されている。(wikipediaより）
うん、まあこれを見ても意味がわからないと思うので、今回は簡単に、「機械学習をサポートしてくれるライブラリ」と覚えておきましょう。
SVMとは サポートベクターマシン（英: support vector machine, SVM）は、教師あり学習を用いるパターン認識モデルの一つである。分類や回帰へ適用できる。 サポートベクターマシンは、現在知られている手法の中でも認識性能が優れた学習モデルの一つである。サポートベクターマシンが優れた認識性能を発揮することができる理由は、未学習データに対して高い識別性能を得るための工夫があるためである。（wikipediaより）
簡単に言うと、下記の画像のように線を引いて、データを分類していく機械学習手法*のことです。 一口に機械学習といっても様々な方法が存在します。 SVM(サポートベクターマシン)はその一つです。
https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/2880px-Kernel_Machine.svg.png (wikipediaより)
目的変数とは 機械学習で予測したい対象です。 例えば、天気を予測したいときの目的変数は晴れや、曇りや雨などになります。
説明変数とは 予測するために必要な情報のことです。 例えば、天気を予測したいときに必要な、降水量や湿度などがこれにあたります。
データ データは基本的には数が多いほど精度が高くなりますが、今回はお試しなので、少なめのデータを用意します。 このデータは今年の天気のデータです。 まあ天気データは気象庁のHPにいくらでもあるので、興味が湧いたら見てみてください。 左から、 気温、降水量、日照時間、湿度、天気(0:晴れ、1:曇り、2:雨) を表しています。 このデータで言うと、気温、降水量、日照時間、湿度までが説明変数、**天気(0:晴れ、1:曇り、2:雨)**が目的変数です。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  6.]]></description>
</item>
<item>
    <title>言語処理100本ノックのための環境構築</title>
    <link>https://ryutaro-a.github.io/ryutaro1104/nlp100-env/</link>
    <pubDate>Sun, 29 May 2022 12:38:06 &#43;0900</pubDate><guid>https://ryutaro-a.github.io/ryutaro1104/nlp100-env/</guid>
    <description><![CDATA[はじめに みなさんは言語処理100本ノックを知っていますか？
言語処理100本ノックとは東工大の岡崎直観先生らによって言語処理を楽しく学ぶことを目的として作成された問題集です。
 私の所属している研究室でも初学者向けの教材として利用されていますが、環境構築で躓いている人がかなりいたため、研究室内のページで環境構築の解説を作成しました。
しかし研究室内向けだけでは勿体ないと思い、この度Qiitanに投稿することにしました。
検索しても言語処理100本ノックのためのまとまった環境構築方法がなかったというのも大きな理由です。
注意 本記事で紹介している環境構築方法は言語処理100本ノックを解くことを主目的としているため、ほかの用途には適さなかったり、無駄が多かったりしますので、予めご了承ください。
また、本記事はWindowsユーザ向けなのでMacユーザの方は適宜読み替えたりしてください。
要望が上がればMac端末で動作を検証してからMac向けの記事を書くかもしれません。
環境構築 まずはWSLを入れよう！ 言語処理100本ノックを解く上で一番簡単かつ解きやすい環境としてWSLというものがあります。
これはubuntuと呼ばれるLinux系のOSをWindows内に仮想的に作れるようにしたツールで、2ステップで簡単に導入できます。
ステップ1 Windows側でWSLが使用できるように機能を有効化します。
wiindowsボタンを押してからwindowsと検索して、Windowsの機能の有効化または無効化という項目をクリックしてください。
画像で言うと赤枠の部分です。
すると様々な項目が表示されるので、Linux用Windowsサブシステムにチェックを入れてください。
こちらも画像で言うと赤枠の部分です。
これでステップ1は完了です。
ステップ2 続いてWSL本体のダウンロードです。
スタート画面などからMicrosoft Storeにアクセスしてubuntuと検索してください。
様々なバージョンが表示されますが、ここではUbuntu20.04LTSをダウンロードしましょう。（ちななみにLTSはLong Time Supportの略、つまり安定板のようなものです）
ダウンロード出来たらスタート画面などから先ほどダウンロードしたUbuntu20.04LTSを起動してください。
Pyenvの導入 Pythonのバージョン管理に便利なPyenvを導入します。
なぜバージョンなんて管理するの？と思われるかもしれません。
言語処理100本ノックを解く上では１つのバージョンで事足りますが、Pythonを使っていると使いたいライブラリが一定のバージョンにしか対応していないなどということがかなりの頻度で現れます。
そんなときにPyenvでバージョンを管理しておくと1つのコマンドを打つだけで好きなバージョンのPythonに切り替えることができます。よって本記事ではPyenvの使用を強く推奨します。
Pyenvの導入は簡単で、WSL上で以下のコマンドをすべて打つだけで終わりです。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 依存パッケージの導入 $ sudo apt install -y build-essential $ sudo apt install -y libffi-dev $ sudo apt install -y libssl-dev # openssl $ sudo apt install -y zlib1g-dev $ sudo apt install -y libbz2-dev libreadline-dev libsqlite3-dev # sqlite3, bz2, readline $ sudo apt install -y git $ cd $ git clone https://github.]]></description>
</item>
</channel>
</rss>
